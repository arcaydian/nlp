{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sFqTI_BIwELH"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"eat\", \"eats\", \"eating\", \"eatable\", \"ate\", \"ability\", \"adjustable\", \"better\"]\n",
        "\n",
        "stemmer = nltk.stem.PorterStemmer()\n",
        "\n",
        "for word in words:\n",
        "  print(\"Word:\", word, \"|\", \"Stemmed:\", stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIZTPRzwwPVf",
        "outputId": "bd4459bd-b4a1-4936-dcdb-29c8800673fb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: eat | Stemmed: eat\n",
            "Word: eats | Stemmed: eat\n",
            "Word: eating | Stemmed: eat\n",
            "Word: eatable | Stemmed: eatabl\n",
            "Word: ate | Stemmed: ate\n",
            "Word: ability | Stemmed: abil\n",
            "Word: adjustable | Stemmed: adjust\n",
            "Word: better | Stemmed: better\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "r9xiIhUPwuGF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"eats eat eating ate adjustable adjusted ability better\")\n",
        "\n",
        "for token in doc:\n",
        "  print(\"Word:\", token.text, \"|\", \"Lemmatized:\", token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euAaFS-QxGKx",
        "outputId": "875fdb49-bc5f-4f7f-f942-850bcfccdd7b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: eats | Lemmatized: eat\n",
            "Word: eat | Lemmatized: eat\n",
            "Word: eating | Lemmatized: eat\n",
            "Word: ate | Lemmatized: eat\n",
            "Word: adjustable | Lemmatized: adjustable\n",
            "Word: adjusted | Lemmatized: adjusted\n",
            "Word: ability | Lemmatized: ability\n",
            "Word: better | Lemmatized: well\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yamOxlsJxn0d",
        "outputId": "02c7da94-19ef-48c0-d11b-c5473266f4c6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhausted\")\n",
        "for token in doc:\n",
        "    print(token.text, \"|\", token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "valc5h4HyNHW",
        "outputId": "8dce3d0e-9a04-4fd2-a3e5-21f7dbbd7d34"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bro | bro\n",
            ", | ,\n",
            "you | you\n",
            "wanna | wanna\n",
            "go | go\n",
            "? | ?\n",
            "Brah | Brah\n",
            ", | ,\n",
            "do | do\n",
            "n't | not\n",
            "say | say\n",
            "no | no\n",
            "! | !\n",
            "I | I\n",
            "am | be\n",
            "exhausted | exhaust\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attribute_ruler = nlp.get_pipe('attribute_ruler')\n",
        "attribute_ruler.add([[{\"TEXT\": \"Bro\"}], [{\"TEXT\": \"Brah\"}]], {\"LEMMA\": \"Brother\"})\n",
        "\n",
        "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhausted\")\n",
        "for token in doc:\n",
        "    print(token.text, \"|\", token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N21aDL40y9I_",
        "outputId": "6f8a1ac4-bafc-484c-e762-a626ae23c080"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bro | Brother\n",
            ", | ,\n",
            "you | you\n",
            "wanna | wanna\n",
            "go | go\n",
            "? | ?\n",
            "Brah | Brother\n",
            ", | ,\n",
            "do | do\n",
            "n't | not\n",
            "say | say\n",
            "no | no\n",
            "! | !\n",
            "I | I\n",
            "am | be\n",
            "exhausted | exhaust\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gJzad74hzjTo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}